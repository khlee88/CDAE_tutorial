{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import batch_norm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set data path\n",
    "test_fold = 0\n",
    "data_name = 'politic_new'\n",
    "data_base_dir = \"../data/\"\n",
    "path = data_base_dir + \"%s\" % data_name + \"/\"\n",
    "\n",
    "train_file_name = 'Train_ratings_fold_' + str(test_fold)\n",
    "test_file_name = 'Test_ratings_fold_' + str(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn shape: (2399876, 3)\n",
      "tst shape: (599968, 3)\n"
     ]
    }
   ],
   "source": [
    "## raw data load\n",
    "### user, item, voting으로 구성된 데이터를 로드하고, -1 voting을 0으로 replace 한다.\n",
    "trn = pd.read_csv(path+train_file_name, sep='\\t', names=['user','item','voting'])\n",
    "tst = pd.read_csv(path+test_file_name, sep='\\t', names=['user','item','voting'])\n",
    "\n",
    "trn = trn.replace(-1, 0)\n",
    "tst = tst.replace(-1, 0)\n",
    "print(\"trn shape:\", trn.shape)\n",
    "print(\"tst shape:\", tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>653</td>\n",
       "      <td>6012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>5908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>654</td>\n",
       "      <td>1464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626</td>\n",
       "      <td>2505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433</td>\n",
       "      <td>5696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  voting\n",
       "0   653  6012       0\n",
       "1   425  5908       1\n",
       "2   654  1464       1\n",
       "3   626  2505       1\n",
       "4  1433  5696       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape all: (1537, 7975) trn: (1536, 7975) tst: (1536, 7975)\n",
      "shape all: (1537, 7975) trn: (1537, 7975) tst: (1537, 7975)\n"
     ]
    }
   ],
   "source": [
    "## pivot data\n",
    "### trn, tst 데이터를 user by item value voting 으로 pivoting 한다.\n",
    "trn_pv = trn.pivot(index='user',columns='item',values='voting')\n",
    "tst_pv = tst.pivot(index='user',columns='item',values='voting')\n",
    "all_pv = pd.concat([trn, tst]).pivot(index='user',columns='item',values='voting')\n",
    "print(\"shape all:\", all_pv.shape, \"trn:\", trn_pv.shape, 'tst:', tst_pv.shape)\n",
    "\n",
    "### tst 데이터의 index가 trn과 맞지 않아 index를 맞춰 주기 위해 다음과 같이 수행한다.\n",
    "### 맞추고자 하는 shape의 index와 column을 0으로 세팅하고 tst_pv를 concat 하면,\n",
    "### row는 union되고 tst_pv에 없는 column은 nan으로 생성된다.\n",
    "### 후에, index를 group by로 min_count=2로 합을 구하는데, min_count=2는 값이 두개 있어야 합계가 계산된다.\n",
    "### 즉, tst_pv에 없었던 column과 row는 nan으로 생성되고 나머지 tst_pv 데이터는 값은 유지된다.\n",
    "all_pv_zero = all_pv.copy()\n",
    "all_pv_zero[:] = 0\n",
    "trn_pv = pd.concat([all_pv_zero, trn_pv]).groupby(level=0).sum(min_count=2)\n",
    "tst_pv = pd.concat([all_pv_zero, tst_pv]).groupby(level=0).sum(min_count=2)\n",
    "print(\"shape all:\", all_pv.shape, \"trn:\", trn_pv.shape, 'tst:', tst_pv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make input data\n",
    "### R은 user by item에서 voting이 1이면 1 아니면 0으로 구성한다.\n",
    "### mask_R은 user by item에서 voting이 1 또는 0 이면 1로 Nan이면 0으로 데이터 여부를 마스킹한다.\n",
    "R = all_pv.fillna(0).values\n",
    "mask_R = all_pv.replace(0.0, 1).fillna(0).values\n",
    "\n",
    "train_R = trn_pv.fillna(0).values\n",
    "train_mask_R = trn_pv.replace(0.0, 1).fillna(0).values\n",
    "\n",
    "test_R = tst_pv.fillna(0).values\n",
    "test_mask_R = tst_pv.replace(0.0, 1).fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]]\n",
      "mask_R\n",
      "[[1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "### index 2 유저는 index 0,4 아이템에 voting 1을 했다. \n",
    "### 그리고 mask_R로 부터 index 2,3 아이템에 voting -1을 한 것을 알 수 있다.\n",
    "### 즉 index 1에는 voting 하지 않았다.\n",
    "print(\"R\")\n",
    "print(R[:5,:5])\n",
    "print(\"mask_R\")\n",
    "print(mask_R[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### train, test의 user, item set을 구성하고 데이터 수를 변수로 저장한다.\n",
    "user_train_set = set(trn['user'])\n",
    "item_train_set = set(trn['item'])\n",
    "\n",
    "user_test_set = set(tst['user'])\n",
    "item_test_set = set(tst['item'])\n",
    "\n",
    "num_users = R.shape[0]\n",
    "num_items = R.shape[1]\n",
    "num_train_ratings = len(trn)\n",
    "num_test_ratings = len(tst)\n",
    "num_total_ratings = num_train_ratings + num_test_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parameter setting\n",
    "hidden_neuron = 50\n",
    "# layer_structure = [num_items, 512, 128, hidden_neuron, 128, 512, num_items]\n",
    "layer_structure = [num_items, 128, hidden_neuron, 128, num_items]\n",
    "lambda_value = 1e-3\n",
    "lr = 1e-3\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "min_RMSE = 99999\n",
    "min_epoch = -99999\n",
    "patience = 0\n",
    "total_patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## place holder\n",
    "### model_mask_corruption은 설정한 random 확률로 0, 1로 된 데이터가 들어간다.\n",
    "model_mask_corruption = tf.placeholder(dtype=tf.float32, shape=[None, num_items])\n",
    "input_R = tf.placeholder(dtype=tf.float32, shape=[None, num_items], name=\"input_R\")\n",
    "input_mask_R = tf.placeholder(dtype=tf.float32, shape=[None, num_items], name=\"input_mask_R\")\n",
    "\n",
    "model_batch_data_idx = tf.placeholder(dtype=tf.int32)\n",
    "real_batch_size = tf.cast(tf.shape(input_R)[0], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### corruption data를 input에 곱해준다. 즉, dropout과 동일하다.\n",
    "corrupted_R = tf.multiply(model_mask_corruption, input_R)\n",
    "corrupted_input_mask_R = tf.multiply(model_mask_corruption, input_mask_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### user embedding matrix를 생성하고 batch user index를 lookup한다.\n",
    "with tf.variable_scope(\"user_scopes\", reuse=tf.AUTO_REUSE):\n",
    "    V = tf.get_variable(name=\"User_embed\", shape=[num_users, layer_structure[1]], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                        dtype=tf.float32)\n",
    "    batch_V = tf.nn.embedding_lookup(V, model_batch_data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### weight initialize\n",
    "def make_layer_weights(n_visible, n_hidden, itr):\n",
    "    with tf.variable_scope(\"SDAE_Variable\"):\n",
    "        pre_W = tf.get_variable(name=(\"pre_W\"+str(itr)), shape=[n_visible, n_hidden], \n",
    "                                initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                                dtype=tf.float32)\n",
    "        pre_b = tf.get_variable(name=(\"pre_b\"+str(itr)), shape=[n_hidden], \n",
    "                                 initializer=tf.zeros_initializer(), dtype=tf.float32)\n",
    "    return pre_W, pre_b\n",
    "\n",
    "### 각 layer 층의 W, b weight을 생성한다.\n",
    "n_layer = len(layer_structure)\n",
    "Weight = dict()\n",
    "bias = dict()\n",
    "for itr in range(n_layer - 1):\n",
    "    Weight[itr], bias[itr] = make_layer_weights(layer_structure[itr], \n",
    "                                                layer_structure[itr + 1], itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <tf.Variable 'SDAE_Variable/pre_W0:0' shape=(7975, 128) dtype=float32_ref>,\n",
       " 1: <tf.Variable 'SDAE_Variable/pre_W1:0' shape=(128, 50) dtype=float32_ref>,\n",
       " 2: <tf.Variable 'SDAE_Variable/pre_W2:0' shape=(50, 128) dtype=float32_ref>,\n",
       " 3: <tf.Variable 'SDAE_Variable/pre_W3:0' shape=(128, 7975) dtype=float32_ref>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate Encoder and CDAE output(Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_normalization = 'FALSE'\n",
    "f_act = tf.nn.sigmoid\n",
    "g_act = tf.nn.sigmoid\n",
    "keep_prob = 1.0\n",
    "\n",
    "hidden_value = corrupted_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for itr1 in range(len(layer_structure) - 1):\n",
    "    ## Encoder \n",
    "    ### encoder 부분으로 첫 레이어에서 batch_V 즉, user data를 넣어준다.\n",
    "    ### batch normal이 True라면 normal을 수행한다.\n",
    "    ### sigmoid로 activation 하였다.\n",
    "    ### matmul -> (batch_normal) -> sigmoid\n",
    "    if itr1 <= int(len(layer_structure) / 2) - 1:\n",
    "        if itr1 == 0:\n",
    "            before_activation = tf.add(\n",
    "                tf.add(tf.matmul(hidden_value, Weight[itr1]), batch_V), bias[itr1])\n",
    "        else:\n",
    "            before_activation = tf.add(tf.matmul(hidden_value, Weight[itr1]), bias[itr1])\n",
    "        if batch_normalization == \"True\":\n",
    "            before_activation = batch_norm(before_activation)\n",
    "        hidden_value = f_act(before_activation)\n",
    "    ## Decoder\n",
    "    ### Encoder와 유사하게 수행한다.\n",
    "    elif itr1 > int(len(layer_structure) / 2) - 1:\n",
    "        before_activation = tf.add(tf.matmul(hidden_value, Weight[itr1]), bias[itr1])\n",
    "        if batch_normalization == \"True\":\n",
    "            before_activation = batch_norm(before_activation)\n",
    "        hidden_value = g_act(before_activation)\n",
    "    ### 마지막 레이어를 제외하고 dropout을 수행한다. \n",
    "    if itr1 < len(layer_structure) - 2: # add dropout except final layer\n",
    "        hidden_value = tf.nn.dropout(hidden_value, keep_prob)\n",
    "    ### Encoder 부분이 끝났을 때, Encoder 변수를 저장한다.\n",
    "    if itr1 == int(len(layer_structure) / 2) - 1:\n",
    "        Encoded_X = hidden_value\n",
    "\n",
    "Decoder = hidden_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## avg reconstruction error term\n",
    "### log cross entropy를 계산한다.\n",
    "pre_cost1 = -1 * tf.multiply(corrupted_R, tf.log(Decoder)) - \\\n",
    "                tf.multiply((1-corrupted_R) , tf.log(1-Decoder))\n",
    "### corrupted_input_mask_R 값을 곱해 기존 존재하던 값만 살린다.\n",
    "pre_cost1 = tf.multiply(pre_cost1, corrupted_input_mask_R)\n",
    "### error의 average를 계산한다.\n",
    "cost1 = tf.reduce_sum(pre_cost1) / tf.cast(real_batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## regularization term\n",
    "### 모든 weight의 paramter의 l2 norm을 합한다.\n",
    "pre_cost2 = tf.constant(0, dtype=tf.float32)\n",
    "for itr in range(len(Weight.keys())):\n",
    "    pre_cost2 = tf.add(pre_cost2,\n",
    "                       tf.add(tf.nn.l2_loss(Weight[itr]), tf.nn.l2_loss(bias[itr])))\n",
    "pre_cost2 = pre_cost2 + tf.nn.l2_loss(batch_V)\n",
    "### lambda value를 곱하여 최종 값을 계산한다.\n",
    "cost2 = lambda_value * 0.5 * pre_cost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cost \n",
    "cost = cost1 + cost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gvs]\n",
    "optimizer = optimizer.apply_gradients(capped_gvs, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(test_R,test_mask_R,Estimated_R,num_test_ratings):\n",
    "\n",
    "    pre_numerator = np.multiply((test_R - Estimated_R), test_mask_R)\n",
    "    numerator = np.sum(np.square(pre_numerator))\n",
    "    denominator = num_test_ratings\n",
    "    RMSE = np.sqrt(numerator / float(denominator))\n",
    "\n",
    "    pre_numeartor = np.multiply((test_R - Estimated_R), test_mask_R)\n",
    "    numerator = np.sum(np.abs(pre_numeartor))\n",
    "    denominator = num_test_ratings\n",
    "    MAE = numerator / float(denominator)\n",
    "\n",
    "    pre_numeartor1 = np.sign(Estimated_R - 0.5)\n",
    "    tmp_test_R = np.sign(test_R - 0.5)\n",
    "\n",
    "    pre_numerator2 = np.multiply((pre_numeartor1 == tmp_test_R), test_mask_R)\n",
    "    numerator = np.sum(pre_numerator2)\n",
    "    denominator = num_test_ratings\n",
    "    ACC = numerator / float(denominator)\n",
    "\n",
    "    a = np.log(Estimated_R)\n",
    "    b = np.log(1 - Estimated_R)\n",
    "    a[a == -np.inf] = 0\n",
    "    b[b == -np.inf] = 0\n",
    "\n",
    "    tmp_r = test_R\n",
    "    tmp_r = a * (tmp_r > 0) + b * (tmp_r == 0)\n",
    "    tmp_r = np.multiply(tmp_r, test_mask_R)\n",
    "    numerator = np.sum(tmp_r)\n",
    "    denominator = num_test_ratings\n",
    "    AVG_loglikelihood = numerator / float(denominator)\n",
    "\n",
    "    return RMSE,MAE,ACC,AVG_loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## tf session start\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "train_cost_list = []\n",
    "test_cost_list = []\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "test_acc_list = []\n",
    "test_avg_loglike_list = []\n",
    "batch_size = 64\n",
    "display_step = 1\n",
    "num_batch = int(num_users / float(batch_size)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training // Epoch 1 // Train cost = 581.02 Elapsed time : 1 sec\n",
      "Testing // Epoch 1 //  Test cost = 154.60\n",
      "RMSE = 0.3527 MAE = 0.2853 ACC = 0.8030378287 AVG Loglike = -0.3953\n",
      "====================================================================================================\n",
      "Training // Epoch 2 // Train cost = 398.45 Elapsed time : 6 sec\n",
      "Testing // Epoch 2 //  Test cost = 138.92\n",
      "RMSE = 0.3451 MAE = 0.2409 ACC = 0.8001610086 AVG Loglike = -0.3549\n",
      "====================================================================================================\n",
      "Training // Epoch 3 // Train cost = 391.33 Elapsed time : 9 sec\n",
      "Testing // Epoch 3 //  Test cost = 136.85\n",
      "RMSE = 0.3442 MAE = 0.2371 ACC = 0.8033845138 AVG Loglike = -0.3496\n",
      "====================================================================================================\n",
      "Training // Epoch 4 // Train cost = 398.86 Elapsed time : 16 sec\n",
      "Testing // Epoch 4 //  Test cost = 136.67\n",
      "RMSE = 0.3447 MAE = 0.2361 ACC = 0.8011877300 AVG Loglike = -0.3491\n",
      "====================================================================================================\n",
      "Training // Epoch 5 // Train cost = 384.07 Elapsed time : 24 sec\n",
      "Testing // Epoch 5 //  Test cost = 136.53\n",
      "RMSE = 0.3447 MAE = 0.2369 ACC = 0.8001676756 AVG Loglike = -0.3487\n",
      "====================================================================================================\n",
      "Training // Epoch 6 // Train cost = 367.76 Elapsed time : 31 sec\n",
      "Testing // Epoch 6 //  Test cost = 135.97\n",
      "RMSE = 0.3439 MAE = 0.2359 ACC = 0.8021644488 AVG Loglike = -0.3473\n",
      "====================================================================================================\n",
      "Training // Epoch 7 // Train cost = 380.06 Elapsed time : 39 sec\n",
      "Testing // Epoch 7 //  Test cost = 135.48\n",
      "RMSE = 0.3430 MAE = 0.2358 ACC = 0.8033861806 AVG Loglike = -0.3459\n",
      "====================================================================================================\n",
      "Training // Epoch 8 // Train cost = 373.31 Elapsed time : 47 sec\n",
      "Testing // Epoch 8 //  Test cost = 135.09\n",
      "RMSE = 0.3416 MAE = 0.2354 ACC = 0.8023411249 AVG Loglike = -0.3448\n",
      "====================================================================================================\n",
      "Training // Epoch 9 // Train cost = 360.32 Elapsed time : 54 sec\n",
      "Testing // Epoch 9 //  Test cost = 134.19\n",
      "RMSE = 0.3396 MAE = 0.2332 ACC = 0.8025244680 AVG Loglike = -0.3424\n",
      "====================================================================================================\n",
      "Training // Epoch 10 // Train cost = 356.58 Elapsed time : 62 sec\n",
      "Testing // Epoch 10 //  Test cost = 133.24\n",
      "RMSE = 0.3375 MAE = 0.2313 ACC = 0.8023177903 AVG Loglike = -0.3398\n",
      "====================================================================================================\n",
      "Training // Epoch 11 // Train cost = 353.70 Elapsed time : 70 sec\n",
      "Testing // Epoch 11 //  Test cost = 132.04\n",
      "RMSE = 0.3354 MAE = 0.2286 ACC = 0.8030061603 AVG Loglike = -0.3366\n",
      "====================================================================================================\n",
      "Training // Epoch 12 // Train cost = 349.86 Elapsed time : 77 sec\n",
      "Testing // Epoch 12 //  Test cost = 129.73\n",
      "RMSE = 0.3315 MAE = 0.2242 ACC = 0.8037595338 AVG Loglike = -0.3305\n",
      "====================================================================================================\n",
      "Training // Epoch 13 // Train cost = 342.16 Elapsed time : 84 sec\n",
      "Testing // Epoch 13 //  Test cost = 124.60\n",
      "RMSE = 0.3222 MAE = 0.2178 ACC = 0.8123116566 AVG Loglike = -0.3173\n",
      "====================================================================================================\n",
      "Training // Epoch 14 // Train cost = 319.55 Elapsed time : 92 sec\n",
      "Testing // Epoch 14 //  Test cost = 113.09\n",
      "RMSE = 0.3004 MAE = 0.2029 ACC = 0.8711031255 AVG Loglike = -0.2876\n",
      "====================================================================================================\n",
      "Training // Epoch 15 // Train cost = 281.03 Elapsed time : 99 sec\n",
      "Testing // Epoch 15 //  Test cost = 95.13\n",
      "RMSE = 0.2651 MAE = 0.1757 ACC = 0.9322180516 AVG Loglike = -0.2414\n",
      "====================================================================================================\n",
      "Training // Epoch 16 // Train cost = 231.49 Elapsed time : 107 sec\n",
      "Testing // Epoch 16 //  Test cost = 79.37\n",
      "RMSE = 0.2346 MAE = 0.1459 ACC = 0.9411285269 AVG Loglike = -0.2007\n",
      "====================================================================================================\n",
      "Training // Epoch 17 // Train cost = 197.71 Elapsed time : 115 sec\n",
      "Testing // Epoch 17 //  Test cost = 70.39\n",
      "RMSE = 0.2187 MAE = 0.1258 ACC = 0.9430936317 AVG Loglike = -0.1775\n",
      "====================================================================================================\n",
      "Training // Epoch 18 // Train cost = 183.23 Elapsed time : 123 sec\n",
      "Testing // Epoch 18 //  Test cost = 65.29\n",
      "RMSE = 0.2108 MAE = 0.1133 ACC = 0.9438353379 AVG Loglike = -0.1642\n",
      "====================================================================================================\n",
      "Training // Epoch 19 // Train cost = 172.34 Elapsed time : 131 sec\n",
      "Testing // Epoch 19 //  Test cost = 62.33\n",
      "RMSE = 0.2068 MAE = 0.1056 ACC = 0.9446703824 AVG Loglike = -0.1564\n",
      "====================================================================================================\n",
      "Training // Epoch 20 // Train cost = 174.92 Elapsed time : 138 sec\n",
      "Testing // Epoch 20 //  Test cost = 60.65\n",
      "RMSE = 0.2050 MAE = 0.1005 ACC = 0.9452320790 AVG Loglike = -0.1519\n",
      "====================================================================================================\n",
      "Training // Epoch 21 // Train cost = 157.79 Elapsed time : 146 sec\n",
      "Testing // Epoch 21 //  Test cost = 59.70\n",
      "RMSE = 0.2044 MAE = 0.0965 ACC = 0.9447520534 AVG Loglike = -0.1492\n",
      "====================================================================================================\n",
      "Training // Epoch 22 // Train cost = 158.88 Elapsed time : 153 sec\n",
      "Testing // Epoch 22 //  Test cost = 58.43\n",
      "RMSE = 0.2026 MAE = 0.0934 ACC = 0.9453704198 AVG Loglike = -0.1458\n",
      "====================================================================================================\n",
      "Training // Epoch 23 // Train cost = 161.35 Elapsed time : 161 sec\n",
      "Testing // Epoch 23 //  Test cost = 57.76\n",
      "RMSE = 0.2018 MAE = 0.0913 ACC = 0.9456120993 AVG Loglike = -0.1440\n",
      "====================================================================================================\n",
      "Training // Epoch 24 // Train cost = 145.96 Elapsed time : 169 sec\n",
      "Testing // Epoch 24 //  Test cost = 57.06\n",
      "RMSE = 0.2010 MAE = 0.0883 ACC = 0.9459637847 AVG Loglike = -0.1420\n",
      "====================================================================================================\n",
      "Training // Epoch 25 // Train cost = 144.35 Elapsed time : 177 sec\n",
      "Testing // Epoch 25 //  Test cost = 56.40\n",
      "RMSE = 0.1998 MAE = 0.0870 ACC = 0.9464904795 AVG Loglike = -0.1402\n",
      "====================================================================================================\n",
      "Training // Epoch 26 // Train cost = 142.78 Elapsed time : 185 sec\n",
      "Testing // Epoch 26 //  Test cost = 55.98\n",
      "RMSE = 0.1992 MAE = 0.0858 ACC = 0.9466338205 AVG Loglike = -0.1390\n",
      "====================================================================================================\n",
      "Training // Epoch 27 // Train cost = 141.47 Elapsed time : 192 sec\n",
      "Testing // Epoch 27 //  Test cost = 55.76\n",
      "RMSE = 0.1989 MAE = 0.0851 ACC = 0.9468688330 AVG Loglike = -0.1383\n",
      "====================================================================================================\n",
      "Training // Epoch 28 // Train cost = 139.03 Elapsed time : 199 sec\n",
      "Testing // Epoch 28 //  Test cost = 55.52\n",
      "RMSE = 0.1986 MAE = 0.0842 ACC = 0.9470188410 AVG Loglike = -0.1376\n",
      "====================================================================================================\n",
      "Training // Epoch 29 // Train cost = 142.27 Elapsed time : 207 sec\n",
      "Testing // Epoch 29 //  Test cost = 55.36\n",
      "RMSE = 0.1986 MAE = 0.0830 ACC = 0.9469455038 AVG Loglike = -0.1371\n",
      "====================================================================================================\n",
      "Training // Epoch 30 // Train cost = 140.33 Elapsed time : 214 sec\n",
      "Testing // Epoch 30 //  Test cost = 55.15\n",
      "RMSE = 0.1982 MAE = 0.0821 ACC = 0.9472171849 AVG Loglike = -0.1364\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training // Epoch 31 // Train cost = 140.23 Elapsed time : 222 sec\n",
      "Testing // Epoch 31 //  Test cost = 55.20\n",
      "RMSE = 0.1983 MAE = 0.0819 ACC = 0.9473221905 AVG Loglike = -0.1364\n",
      "====================================================================================================\n",
      "Training // Epoch 32 // Train cost = 138.29 Elapsed time : 229 sec\n",
      "Testing // Epoch 32 //  Test cost = 54.96\n",
      "RMSE = 0.1978 MAE = 0.0814 ACC = 0.9474821991 AVG Loglike = -0.1357\n",
      "====================================================================================================\n",
      "Training // Epoch 33 // Train cost = 140.95 Elapsed time : 237 sec\n",
      "Testing // Epoch 33 //  Test cost = 54.79\n",
      "RMSE = 0.1977 MAE = 0.0803 ACC = 0.9473788602 AVG Loglike = -0.1352\n",
      "====================================================================================================\n",
      "Training // Epoch 34 // Train cost = 144.73 Elapsed time : 246 sec\n",
      "Testing // Epoch 34 //  Test cost = 55.00\n",
      "RMSE = 0.1981 MAE = 0.0802 ACC = 0.9474888661 AVG Loglike = -0.1357\n",
      "====================================================================================================\n",
      "Training // Epoch 35 // Train cost = 135.55 Elapsed time : 254 sec\n",
      "Testing // Epoch 35 //  Test cost = 55.00\n",
      "RMSE = 0.1983 MAE = 0.0790 ACC = 0.9470155075 AVG Loglike = -0.1355\n",
      "====================================================================================================\n",
      "Training // Epoch 36 // Train cost = 133.73 Elapsed time : 262 sec\n",
      "Testing // Epoch 36 //  Test cost = 54.66\n",
      "RMSE = 0.1975 MAE = 0.0785 ACC = 0.9476088725 AVG Loglike = -0.1346\n",
      "====================================================================================================\n",
      "Training // Epoch 37 // Train cost = 133.46 Elapsed time : 269 sec\n",
      "Testing // Epoch 37 //  Test cost = 54.45\n",
      "RMSE = 0.1970 MAE = 0.0785 ACC = 0.9478022161 AVG Loglike = -0.1340\n",
      "====================================================================================================\n",
      "Training // Epoch 38 // Train cost = 132.67 Elapsed time : 276 sec\n",
      "Testing // Epoch 38 //  Test cost = 54.41\n",
      "RMSE = 0.1969 MAE = 0.0782 ACC = 0.9477155448 AVG Loglike = -0.1338\n",
      "====================================================================================================\n",
      "Training // Epoch 39 // Train cost = 137.16 Elapsed time : 284 sec\n",
      "Testing // Epoch 39 //  Test cost = 54.25\n",
      "RMSE = 0.1966 MAE = 0.0781 ACC = 0.9480238946 AVG Loglike = -0.1333\n",
      "====================================================================================================\n",
      "Training // Epoch 40 // Train cost = 132.75 Elapsed time : 292 sec\n",
      "Testing // Epoch 40 //  Test cost = 54.36\n",
      "RMSE = 0.1969 MAE = 0.0779 ACC = 0.9478522188 AVG Loglike = -0.1335\n",
      "====================================================================================================\n",
      "Training // Epoch 41 // Train cost = 133.01 Elapsed time : 300 sec\n",
      "Testing // Epoch 41 //  Test cost = 54.34\n",
      "RMSE = 0.1968 MAE = 0.0774 ACC = 0.9478472185 AVG Loglike = -0.1334\n",
      "====================================================================================================\n",
      "Training // Epoch 42 // Train cost = 130.77 Elapsed time : 307 sec\n",
      "Testing // Epoch 42 //  Test cost = 54.28\n",
      "RMSE = 0.1966 MAE = 0.0770 ACC = 0.9480605632 AVG Loglike = -0.1331\n",
      "====================================================================================================\n",
      "Training // Epoch 43 // Train cost = 131.19 Elapsed time : 314 sec\n",
      "Testing // Epoch 43 //  Test cost = 54.20\n",
      "RMSE = 0.1965 MAE = 0.0766 ACC = 0.9480388954 AVG Loglike = -0.1329\n",
      "====================================================================================================\n",
      "Training // Epoch 44 // Train cost = 141.09 Elapsed time : 322 sec\n",
      "Testing // Epoch 44 //  Test cost = 54.40\n",
      "RMSE = 0.1969 MAE = 0.0766 ACC = 0.9478338845 AVG Loglike = -0.1333\n",
      "====================================================================================================\n",
      "Training // Epoch 45 // Train cost = 132.91 Elapsed time : 331 sec\n",
      "Testing // Epoch 45 //  Test cost = 54.75\n",
      "RMSE = 0.1976 MAE = 0.0770 ACC = 0.9474738653 AVG Loglike = -0.1341\n",
      "====================================================================================================\n",
      "Training // Epoch 46 // Train cost = 141.19 Elapsed time : 339 sec\n",
      "Testing // Epoch 46 //  Test cost = 54.51\n",
      "RMSE = 0.1970 MAE = 0.0765 ACC = 0.9479472239 AVG Loglike = -0.1334\n",
      "====================================================================================================\n",
      "Training // Epoch 47 // Train cost = 131.60 Elapsed time : 347 sec\n",
      "Testing // Epoch 47 //  Test cost = 54.59\n",
      "RMSE = 0.1973 MAE = 0.0764 ACC = 0.9474888661 AVG Loglike = -0.1336\n",
      "====================================================================================================\n",
      "Training // Epoch 48 // Train cost = 135.48 Elapsed time : 356 sec\n",
      "Testing // Epoch 48 //  Test cost = 54.59\n",
      "RMSE = 0.1971 MAE = 0.0761 ACC = 0.9477822151 AVG Loglike = -0.1335\n",
      "====================================================================================================\n",
      "Training // Epoch 49 // Train cost = 134.37 Elapsed time : 363 sec\n",
      "Testing // Epoch 49 //  Test cost = 54.30\n",
      "RMSE = 0.1963 MAE = 0.0759 ACC = 0.9483189103 AVG Loglike = -0.1326\n",
      "====================================================================================================\n",
      "Training // Epoch 50 // Train cost = 134.95 Elapsed time : 371 sec\n",
      "Testing // Epoch 50 //  Test cost = 54.60\n",
      "RMSE = 0.1969 MAE = 0.0756 ACC = 0.9479105552 AVG Loglike = -0.1333\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for itr in range(epoch):\n",
    "    ## corruption data 생성 및 user shuffle\n",
    "    corruption_level = 0.3\n",
    "    mask_corruption_np = np.random.binomial(1, 1 - corruption_level, (num_users, num_items))\n",
    "    random_perm_doc_idx = np.random.permutation(num_users)\n",
    "    batch_cost = 0\n",
    "    for i in range(num_batch):\n",
    "        if i == num_batch - 1:\n",
    "            batch_set_idx = random_perm_doc_idx[i * batch_size:]\n",
    "        elif i < num_batch -1:\n",
    "            batch_set_idx = random_perm_doc_idx[i * batch_size : (i+1) * batch_size]\n",
    "\n",
    "        _, Cost = sess.run([optimizer, cost], \n",
    "                           feed_dict={model_mask_corruption: mask_corruption_np[batch_set_idx, :],\n",
    "                                      input_R: train_R[batch_set_idx, :],\n",
    "                                      input_mask_R: train_mask_R[batch_set_idx, :],\n",
    "                                      model_batch_data_idx: batch_set_idx})\n",
    "        batch_cost = batch_cost + Cost\n",
    "\n",
    "    if i % display_step == 0:\n",
    "        print (\"Training //\", \"Epoch %d //\" % (itr+1),  \n",
    "               \"Train cost = {:.2f}\".format(batch_cost/num_batch), \n",
    "               \"Elapsed time : %d sec\" % (time.time() - start_time))\n",
    "    \n",
    "    '''test''' \n",
    "    ## validation 및 test에서는 corruption을 하지 않는다.\n",
    "    mask_corruption_np = np.random.binomial(1, 1 - 0, (num_users, num_items))\n",
    "    batch_set_idx = np.arange(num_users)\n",
    "    \n",
    "    Cost, decoder = sess.run([cost, Decoder],\n",
    "                        feed_dict={model_mask_corruption: mask_corruption_np, \n",
    "                                   input_R: test_R,\n",
    "                                   input_mask_R: test_mask_R,\n",
    "                                   model_batch_data_idx: batch_set_idx})\n",
    "    test_cost_list.append(Cost)\n",
    "    Estimated_R = decoder.clip(min=0, max=1)\n",
    "    RMSE, MAE, ACC, AVG_loglikelihood = evaluation(test_R, test_mask_R, \n",
    "                                               Estimated_R, num_test_ratings)\n",
    "    test_rmse_list.append(RMSE)\n",
    "    test_mae_list.append(MAE)\n",
    "    test_acc_list.append(ACC)\n",
    "    test_avg_loglike_list.append(AVG_loglikelihood)\n",
    "    \n",
    "    if itr % display_step == 0:\n",
    "        print(\"Testing //\", \"Epoch %d //\" % (itr+1), \" Test cost = {:.2f}\".format(Cost))\n",
    "        print(\"RMSE = {:.4f}\".format(RMSE), \"MAE = {:.4f}\".format(MAE), \n",
    "              \"ACC = {:.10f}\".format(ACC), \"AVG Loglike = {:.4f}\".format(AVG_loglikelihood))\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "    if RMSE <= min_RMSE:\n",
    "        min_RMSE = RMSE\n",
    "        min_epoch = itr\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience = patience + 1\n",
    "        \n",
    "    if (itr > 100) and (patience >= total_patience):\n",
    "        test_rmse_list.append(test_rmse_list[min_epoch])\n",
    "        test_mae_list.append(test_mae_list[min_epoch])\n",
    "        test_acc_list.append(test_acc_list[min_epoch])\n",
    "        test_avg_loglike_list.append(test_avg_loglike_list[min_epoch])\n",
    "        earlystop_switch = True\n",
    "        print (\"========== Early Stopping at Epoch %d\" %itr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
